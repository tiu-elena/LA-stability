{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import shap\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pickle\n",
    "from sklearn.model_selection import GridSearchCV,StratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from evidently.report import Report\n",
    "from evidently.metrics import DataDriftTable\n",
    "from evidently.metrics import DatasetDriftMetric\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "from scipy import stats\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import optuna "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent_feature = ['Passed first attempt?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_features = ['BINGEING OF SESSIONS',\n",
    " 'CONSTANCY OF CLICKS',\n",
    " 'CONSTANCY OF SESSION LENGTH',\n",
    " 'MEDIAN DIFF. BETWEEN ACTIVE DAYS',\n",
    " 'MEDIAN NUMBER OF ACTIONS PER SESSION',\n",
    " 'MEDIAN NUMBER OF ACTIVE DAYS PER WEEK',\n",
    " 'MEDIAN SESSION DURATION',\n",
    " 'PROPORTION OF ACTIVE DAYS',\n",
    " 'PROPORTION OF FIRST-DAY-OF-WEEK ACTIVITY',\n",
    " 'PROPORTION OF POSTS READ',\n",
    " 'PROPORTION OF WEEKS WITH FIRST-DAY ACTIVITY',\n",
    " 'REGULARITY OF SESSIONS',\n",
    " 'TOTAL NUMBER OF CREATED POSTS',\n",
    " 'TOTAL NUMBER OF SESSIONS',\n",
    " 'TOTAL SESSIONS DURATION',\n",
    " 'UNIFORMITY OF SESSIONS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis parameter specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_start = '1920'\n",
    "year_finish = '2021'\n",
    "course_name = 'De globale economie'\n",
    "exam_month = 'juni'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '1819'\n",
    "data_1819 = pd.read_excel(f'data/{course_name}_{year}_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '1920'\n",
    "data_1920 = pd.read_excel(f'data/{course_name}_{year}_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2021'\n",
    "data_2021 = pd.read_excel(f'data/{course_name}_{year}_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (year_start == '1920' and year_finish == '2021'):\n",
    "\n",
    "    X_y1 = data_1920[independent_features].copy().to_numpy()\n",
    "    y_y1 = data_1920[dependent_feature].copy().to_numpy()\n",
    "\n",
    "    X_y2 = data_2021[independent_features].copy().to_numpy()\n",
    "    y_y2 = data_2021[dependent_feature].copy().to_numpy()\n",
    "\n",
    "elif (year_start == '1819' and year_finish == '1920'):\n",
    "    X_y1 = data_1819[independent_features].copy().to_numpy()\n",
    "    y_y1 = data_1819[dependent_feature].copy().to_numpy()\n",
    "\n",
    "    X_y2 = data_1920[independent_features].copy().to_numpy()\n",
    "    y_y2 = data_1920[dependent_feature].copy().to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data drift analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1819 vs. 1920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drift_dataset_report = Report(metrics = [\n",
    "    DatasetDriftMetric(stattest_threshold = 0.025),\n",
    "    DataDriftTable()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drift_dataset_report.run(reference_data = data_1819[independent_features],\n",
    "                              current_data = data_1920[independent_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the report can be seen in online appendices\n",
    "data_drift_dataset_report.show(mode = 'inline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1920 vs. 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drift_dataset_report.run(reference_data = data_1920[independent_features],\n",
    "                              current_data = data_2021[independent_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the report can be seen in online appendices\n",
    "data_drift_dataset_report.show(mode = 'inline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi(score_initial, score_new, num_bins = 10):\n",
    "    \n",
    "    eps = 1e-4\n",
    "    \n",
    "    score_initial.sort()\n",
    "    score_new.sort()\n",
    "    \n",
    "    min_val = min(min(score_initial), min(score_new))\n",
    "    max_val = max(max(score_initial), max(score_new))\n",
    "\n",
    "    bins = [min_val + (max_val - min_val)*(i)/num_bins for i in range(num_bins+1)]\n",
    "\n",
    "    bins[0] = min_val - eps \n",
    "    bins[-1] = max_val + eps \n",
    "          \n",
    "    bins_initial = pd.cut(score_initial, bins = bins, labels = range(1,num_bins+1))\n",
    "    df_initial = pd.DataFrame({'initial': score_initial, 'bin': bins_initial})\n",
    "    grp_initial = df_initial.groupby('bin').count()\n",
    "    grp_initial['percent_initial'] = grp_initial['initial'] / sum(grp_initial['initial'])\n",
    "    \n",
    "    bins_new = pd.cut(score_new, bins = bins, labels = range(1,num_bins+1))\n",
    "    df_new = pd.DataFrame({'new': score_new, 'bin': bins_new})\n",
    "    grp_new = df_new.groupby('bin').count()\n",
    "    grp_new['percent_new'] = grp_new['new'] / sum(grp_new['new'])\n",
    "    \n",
    "    psi_df = grp_initial.join(grp_new, on = \"bin\", how = \"inner\")\n",
    "    \n",
    "    psi_df['percent_initial'] = psi_df['percent_initial'].apply(lambda x: eps if x == 0 else x)\n",
    "    psi_df['percent_new'] = psi_df['percent_new'].apply(lambda x: eps if x == 0 else x)\n",
    "    \n",
    "    psi_df['psi'] = (psi_df['percent_initial'] - psi_df['percent_new']) * np.log(psi_df['percent_initial'] / psi_df['percent_new'])\n",
    "    \n",
    "    return np.sum(psi_df['psi'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models_scaled(model, model_name, param_grid):\n",
    "    inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "    psi_scores_y1_y2 = []\n",
    "    psi_scores_y1_y2_retrained = []\n",
    "    psi_scores_y1_y2_cv = []\n",
    "\n",
    "    outer_scores_y1 = []\n",
    "    shap_scores_y1 = []\n",
    "\n",
    "    outer_scores_y2 = []\n",
    "    shap_scores_y2 = []\n",
    "\n",
    "    outer_scores_y2_retrained = []\n",
    "    shap_scores_y2_retrained = []\n",
    "\n",
    "    outer_scores_y2_cv = []\n",
    "    shap_scores_y2_cv = []\n",
    "\n",
    "    ix_training_y1, ix_test_y1 = [], []\n",
    "    ix_training_y2, ix_test_y2 = [], []\n",
    "\n",
    "    shaps_y1_per_fold = {}\n",
    "    shaps_y2_per_fold = {}\n",
    "    shaps_y2_retrained_per_fold = {}\n",
    "    shaps_y2_cv_per_fold = {}\n",
    "\n",
    "    for fold in outer_cv.split(X_y1, y_y1):\n",
    "        ix_training_y1.append(fold[0]), ix_test_y1.append(fold[1])\n",
    "\n",
    "    for fold in outer_cv.split(X_y2, y_y2):\n",
    "        ix_training_y2.append(fold[0]), ix_test_y2.append(fold[1])\n",
    "\n",
    "    \n",
    "    for i in range(10):  \n",
    "\n",
    "        train_idX_y1, test_idX_y1 = ix_training_y1[i], ix_test_y1[i]\n",
    "        train_idX_y2, test_idX_y2 = ix_training_y2[i], ix_test_y2[i]\n",
    "\n",
    "        mms = MinMaxScaler()\n",
    "\n",
    "        X_train_y1_scaled = mms.fit_transform(X_y1[train_idX_y1].copy())\n",
    "        X_train_y1_scaled = pd.DataFrame(X_train_y1_scaled)\n",
    "        X_train_y1_scaled.columns = independent_features\n",
    "\n",
    "        X_test_y1_scaled = mms.transform(X_y1[test_idX_y1].copy())\n",
    "        X_test_y1_scaled = pd.DataFrame(X_test_y1_scaled)\n",
    "        X_test_y1_scaled.columns = independent_features\n",
    "\n",
    "        mms = MinMaxScaler()\n",
    "\n",
    "        X_train_y2_scaled = mms.fit_transform(X_y2[train_idX_y2].copy())\n",
    "        X_train_y2_scaled = pd.DataFrame(X_train_y2_scaled)\n",
    "        X_train_y2_scaled.columns = independent_features\n",
    "\n",
    "        X_test_y2_scaled = mms.transform(X_y2[test_idX_y2].copy())\n",
    "        X_test_y2_scaled = pd.DataFrame(X_test_y2_scaled)\n",
    "        X_test_y2_scaled.columns = independent_features\n",
    "\n",
    "        # step 1)\n",
    "        param_grid = param_grid\n",
    "        gcv = GridSearchCV(estimator=model,\n",
    "                            param_grid=param_grid,\n",
    "                            scoring='balanced_accuracy',\n",
    "                            n_jobs=-1,\n",
    "                            cv=inner_cv,\n",
    "                            verbose=0,\n",
    "                            refit=True)\n",
    "        gcv.fit(X_train_y1_scaled, y_y1[train_idX_y1])\n",
    "        best_model = gcv.best_estimator_\n",
    "        print(f'Step {i} for model {model_name}')\n",
    "        print('\\n        Best ACCURACY y1 model %.2f%%' % (gcv.best_score_ * 100))\n",
    "        print('        Best parameters 1819 model:', gcv.best_params_)\n",
    "        \n",
    "        # step 2) \n",
    "        y_pred = best_model.predict(X_test_y1_scaled)\n",
    "        outer_scores_y1.append(balanced_accuracy_score(y_y1[test_idX_y1], y_pred))\n",
    "        print('ACCURACY y1 (on outer test fold) %.2f%%' % (outer_scores_y1[-1]*100))\n",
    "\n",
    "        # step 3) \n",
    "        explainer_y1 = shap.KernelExplainer(best_model.predict_proba, shap.sample(X_train_y1_scaled,100))\n",
    "        shap_values_y1 = explainer_y1.shap_values(X_test_y1_scaled)\n",
    "        for SHAPs in shap_values_y1[1]:\n",
    "            shap_scores_y1.append(SHAPs)\n",
    "        shaps_y1_per_fold[i] = shap_values_y1[1]\n",
    "\n",
    "        # step 4)  \n",
    "        y_pred = best_model.predict(X_test_y2_scaled)\n",
    "        outer_scores_y2.append(balanced_accuracy_score(y_y2[test_idX_y2], y_pred))\n",
    "        print('ACCURACY y2 (on outer test fold) %.2f%%' % (outer_scores_y2[-1]*100))\n",
    "        probas_y1 = best_model.predict_proba(X_test_y1_scaled)[:,1]\n",
    "        probas_y2 = best_model.predict_proba(X_test_y2_scaled)[:,1]\n",
    "        psi_scores_y1_y2.append(psi(probas_y1,\n",
    "                                     probas_y2))\n",
    "\n",
    "        # step 5)\n",
    "        shap_values_y2 = explainer_y1.shap_values(X_test_y2_scaled)\n",
    "        for SHAPs in shap_values_y2[1]:\n",
    "            shap_scores_y2.append(SHAPs) \n",
    "        shaps_y2_per_fold[i] = shap_values_y2[1]\n",
    "\n",
    "        # step 6)\n",
    "        best_model.fit(X_train_y2_scaled, y_y2[train_idX_y2])\n",
    "\n",
    "        # step 7)\n",
    "        y_pred = best_model.predict(X_test_y2_scaled)\n",
    "        outer_scores_y2_retrained.append(balanced_accuracy_score(y_y2[test_idX_y2], y_pred))\n",
    "        print('ACCURACY y2 retrained (on outer test fold) %.2f%%' % (outer_scores_y2_retrained[-1]*100))\n",
    "        probas_y2_retrained = best_model.predict_proba(X_test_y2_scaled)[:,1]\n",
    "        psi_scores_y1_y2_retrained.append(psi(probas_y1,\n",
    "                                               probas_y2_retrained))\n",
    "\n",
    "        # step 8)\n",
    "        explainer_y2_retrained = shap.KernelExplainer(best_model.predict_proba, shap.sample(X_train_y2_scaled,100))\n",
    "        shap_values_y2_retrained = explainer_y2_retrained.shap_values(X_test_y2_scaled)\n",
    "        for SHAPs in shap_values_y2_retrained[1]:\n",
    "            shap_scores_y2_retrained.append(SHAPs) \n",
    "        shaps_y2_retrained_per_fold[i] = shap_values_y2_retrained[1]\n",
    "\n",
    "        #step 9) \n",
    "\n",
    "        gcv_y2 = GridSearchCV(estimator=model,\n",
    "                        param_grid=param_grid,\n",
    "                        scoring='balanced_accuracy',\n",
    "                        n_jobs=-1,\n",
    "                        cv=inner_cv,\n",
    "                        verbose=0,\n",
    "                        refit=True)\n",
    "        \n",
    "        gcv_y2.fit(X_train_y2_scaled, y_y2[train_idX_y2]) \n",
    "        best_model_y2 = gcv_y2.best_estimator_\n",
    "        print('\\n        Best ACCURACY y2 CV model %.2f%%' % (gcv_y2.best_score_ * 100))\n",
    "        print('        Best parameters:', gcv_y2.best_params_)\n",
    "\n",
    "        # step 10)\n",
    "        y_pred = best_model_y2.predict(X_test_y2_scaled)\n",
    "        outer_scores_y2_cv.append(balanced_accuracy_score(y_y2[test_idX_y2], y_pred))\n",
    "        print('ACCURACY y2 after CV (on outer test fold) %.2f%%' % (outer_scores_y2_cv[-1]*100))\n",
    "        probas_y2_cv = best_model_y2.predict_proba(X_test_y2_scaled)[:,1]\n",
    "        psi_scores_y1_y2_cv.append(psi(probas_y1,\n",
    "                                        probas_y2_cv))\n",
    "\n",
    "        #step 11)\n",
    "        explainer_y2_cv = shap.KernelExplainer(best_model_y2.predict_proba, shap.sample(X_train_y2_scaled,100))\n",
    "        shap_values_y2_cv = explainer_y2_cv.shap_values(X_test_y2_scaled)\n",
    "        for SHAPs in shap_values_y2_cv[1]:\n",
    "            shap_scores_y2_cv.append(SHAPs)\n",
    "        shaps_y2_cv_per_fold[i] = shap_values_y2_cv[1]\n",
    "    \n",
    "    return outer_scores_y1, shap_scores_y1, outer_scores_y2,\\\n",
    "    shap_scores_y2, outer_scores_y2_retrained, shap_scores_y2_retrained,\\\n",
    "    outer_scores_y2_cv, shap_scores_y2_cv, ix_training_y1, ix_test_y1,\\\n",
    "    ix_training_y2, ix_test_y2, shaps_y1_per_fold, shaps_y2_per_fold,\\\n",
    "          shaps_y2_retrained_per_fold, shaps_y2_cv_per_fold,\\\n",
    "          psi_scores_y1_y2,\\\n",
    "              psi_scores_y1_y2_retrained, psi_scores_y1_y2_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(model, model_name, param_grid):\n",
    "    inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "    psi_scores_y1_y2 = []\n",
    "    psi_scores_y1_y2_retrained = []\n",
    "    psi_scores_y1_y2_cv = []\n",
    "\n",
    "    outer_scores_y1 = []\n",
    "    shap_scores_y1 = []\n",
    "\n",
    "    outer_scores_y2 = []\n",
    "    shap_scores_y2 = []\n",
    "\n",
    "    outer_scores_y2_retrained = []\n",
    "    shap_scores_y2_retrained = []\n",
    "\n",
    "    outer_scores_y2_cv = []\n",
    "    shap_scores_y2_cv = []\n",
    "\n",
    "    ix_training_y1, ix_test_y1 = [], []\n",
    "    ix_training_y2, ix_test_y2 = [], []\n",
    "\n",
    "    shaps_y1_per_fold = {}\n",
    "    shaps_y2_per_fold = {}\n",
    "    shaps_y2_retrained_per_fold = {}\n",
    "    shaps_y2_cv_per_fold = {}\n",
    "\n",
    "    for fold in outer_cv.split(X_y1, y_y1):\n",
    "        ix_training_y1.append(fold[0]), ix_test_y1.append(fold[1])\n",
    "\n",
    "    for fold in outer_cv.split(X_y2, y_y2):\n",
    "        ix_training_y2.append(fold[0]), ix_test_y2.append(fold[1])\n",
    "\n",
    "    \n",
    "    for i in range(10):  \n",
    "\n",
    "        train_idX_y1, test_idX_y1 = ix_training_y1[i], ix_test_y1[i]\n",
    "        train_idX_y2, test_idX_y2 = ix_training_y2[i], ix_test_y2[i]\n",
    "        \n",
    "        # step 1)\n",
    "        param_grid = param_grid\n",
    "        gcv = GridSearchCV(estimator=model,\n",
    "                            param_grid=param_grid,\n",
    "                            scoring='balanced_accuracy',\n",
    "                            n_jobs=-1,\n",
    "                            cv=inner_cv,\n",
    "                            verbose=0,\n",
    "                            refit=True)\n",
    "        \n",
    "        gcv.fit(X_y1[train_idX_y1], y_y1[train_idX_y1]) \n",
    "        best_model = gcv.best_estimator_\n",
    "        print(f'Step {i} for model {model_name}')\n",
    "        print('\\n        Best ACCURACY y1 model %.2f%%' % (gcv.best_score_ * 100))\n",
    "        print('        Best parameters 1819 model:', gcv.best_params_)\n",
    "        \n",
    "        # step 2) \n",
    "        y_pred = best_model.predict(X_y1[test_idX_y1])\n",
    "        outer_scores_y1.append(balanced_accuracy_score(y_y1[test_idX_y1], y_pred))\n",
    "        print('ACCURACY y1 (on outer test fold) %.2f%%' % (outer_scores_y1[-1]*100))\n",
    "\n",
    "        # step 3) \n",
    "        explainer_y1 = shap.KernelExplainer(best_model.predict_proba, shap.sample(X_y1[train_idX_y1],100))\n",
    "        shap_values_y1 = explainer_y1.shap_values(X_y1[test_idX_y1])\n",
    "        for SHAPs in shap_values_y1[1]:\n",
    "            shap_scores_y1.append(SHAPs)\n",
    "        shaps_y1_per_fold[i] = shap_values_y1[1]\n",
    "\n",
    "        # step 4)  \n",
    "        y_pred = best_model.predict(X_y2[test_idX_y2])\n",
    "        outer_scores_y2.append(balanced_accuracy_score(y_y2[test_idX_y2], y_pred))\n",
    "        print('ACCURACY y2 (on outer test fold) %.2f%%' % (outer_scores_y2[-1]*100))\n",
    "        probas_y1 = best_model.predict_proba(X_y1[test_idX_y1])[:,1]\n",
    "        probas_y2 = best_model.predict_proba(X_y2[test_idX_y2])[:,1]\n",
    "        psi_scores_y1_y2.append(psi(probas_y1,\n",
    "                                     probas_y2))\n",
    "\n",
    "        # step 5)\n",
    "        shap_values_y2 = explainer_y1.shap_values(X_y2[test_idX_y2])\n",
    "        for SHAPs in shap_values_y2[1]:\n",
    "            shap_scores_y2.append(SHAPs) \n",
    "        shaps_y2_per_fold[i] = shap_values_y2[1]\n",
    "\n",
    "        # step 6)\n",
    "        best_model.fit(X_y2[train_idX_y2], y_y2[train_idX_y2])\n",
    "\n",
    "        # step 7)\n",
    "        y_pred = best_model.predict(X_y2[test_idX_y2])\n",
    "        outer_scores_y2_retrained.append(balanced_accuracy_score(y_y2[test_idX_y2], y_pred))\n",
    "        print('ACCURACY y2 retrained (on outer test fold) %.2f%%' % (outer_scores_y2_retrained[-1]*100))\n",
    "        probas_y2_retrained = best_model.predict_proba(X_y2[test_idX_y2])[:,1]\n",
    "        psi_scores_y1_y2_retrained.append(psi(probas_y1,\n",
    "                                               probas_y2_retrained))\n",
    "\n",
    "        # step 8)\n",
    "        explainer_y2_retrained = shap.KernelExplainer(best_model.predict_proba, shap.sample(X_y2[train_idX_y2],100))\n",
    "        shap_values_y2_retrained = explainer_y2_retrained.shap_values(X_y2[test_idX_y2])\n",
    "        for SHAPs in shap_values_y2_retrained[1]:\n",
    "            shap_scores_y2_retrained.append(SHAPs) \n",
    "        shaps_y2_retrained_per_fold[i] = shap_values_y2_retrained[1]\n",
    "\n",
    "        #step 9) \n",
    "\n",
    "        gcv_y2 = GridSearchCV(estimator=model,\n",
    "                        param_grid=param_grid,\n",
    "                        scoring='balanced_accuracy',\n",
    "                        n_jobs=-1,\n",
    "                        cv=inner_cv,\n",
    "                        verbose=0,\n",
    "                        refit=True)\n",
    "        \n",
    "        gcv_y2.fit(X_y2[train_idX_y2], y_y2[train_idX_y2])\n",
    "        best_model_y2 = gcv_y2.best_estimator_\n",
    "        print('\\n        Best ACCURACY y2 CV model %.2f%%' % (gcv_y2.best_score_ * 100))\n",
    "        print('        Best parameters:', gcv_y2.best_params_)\n",
    "\n",
    "        # step 10)\n",
    "        y_pred = best_model_y2.predict(X_y2[test_idX_y2])\n",
    "        outer_scores_y2_cv.append(balanced_accuracy_score(y_y2[test_idX_y2], y_pred))\n",
    "        print('ACCURACY y2 after CV (on outer test fold) %.2f%%' % (outer_scores_y2_cv[-1]*100))\n",
    "        probas_y2_cv = best_model_y2.predict_proba(X_y2[test_idX_y2])[:,1]\n",
    "        psi_scores_y1_y2_cv.append(psi(probas_y1,\n",
    "                                        probas_y2_cv))\n",
    "\n",
    "        #step 11)\n",
    "        explainer_y2_cv = shap.KernelExplainer(best_model_y2.predict_proba, shap.sample(X_y2[train_idX_y2],100))\n",
    "        shap_values_y2_cv = explainer_y2_cv.shap_values(X_y2[test_idX_y2])\n",
    "        for SHAPs in shap_values_y2_cv[1]:\n",
    "            shap_scores_y2_cv.append(SHAPs)\n",
    "        shaps_y2_cv_per_fold[i] = shap_values_y2_cv[1]\n",
    "\n",
    "    return outer_scores_y1, shap_scores_y1, outer_scores_y2,\\\n",
    "          shap_scores_y2, outer_scores_y2_retrained, shap_scores_y2_retrained,\\\n",
    "              outer_scores_y2_cv, shap_scores_y2_cv, ix_training_y1, ix_test_y1,\\\n",
    "                  ix_training_y2, ix_test_y2,shaps_y1_per_fold, shaps_y2_per_fold,\\\n",
    "          shaps_y2_retrained_per_fold, shaps_y2_cv_per_fold,\\\n",
    "          psi_scores_y1_y2,\\\n",
    "              psi_scores_y1_y2_retrained, psi_scores_y1_y2_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_outer_scores_y1, nb_shap_scores_y1, nb_outer_scores_y2, nb_shap_scores_y2,\\\n",
    "      nb_outer_scores_y2_retrained, nb_shap_scores_y2_retrained, nb_outer_scores_y2_cv,\\\n",
    "          nb_shap_scores_y2_cv, nb_ix_training_y1, nb_ix_test_y1, nb_ix_training_y2,\\\n",
    "              nb_ix_test_y2, nb_shaps_y1_per_fold, nb_shaps_y2_per_fold,\\\n",
    "          nb_shaps_y2_retrained_per_fold, nb_shaps_y2_cv_per_fold,\\\n",
    "            nb_psi_scores_y1_y2,\\\n",
    "              nb_psi_scores_y1_y2_retrained, nb_psi_scores_y1_y2_cv= run_models(GaussianNB(), 'NB',\n",
    "                                                                                    [{'var_smoothing': np.logspace(0,-9, num=100)}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = independent_features\n",
    "\n",
    "resultX = pd.DataFrame(nb_shap_scores_y1, columns = feature_names)\n",
    "vals = np.abs(resultX.values).mean(0)\n",
    "shap_importance_nb = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance_nb.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance_nb['Rank'] = len(stats.rankdata(shap_importance_nb['feature_importance_vals'])) \\\n",
    "    - stats.rankdata(shap_importance_nb['feature_importance_vals']) + 1\n",
    "\n",
    "resultX = pd.DataFrame(nb_shap_scores_y2, columns = feature_names)\n",
    "vals = np.abs(resultX.values).mean(0)\n",
    "shap_importance_nb_y2 = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance_nb_y2.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance_nb_y2['Rank'] = len(stats.rankdata(shap_importance_nb_y2['feature_importance_vals'])) \\\n",
    "    - stats.rankdata(shap_importance_nb_y2['feature_importance_vals']) + 1\n",
    "\n",
    "resultX = pd.DataFrame(nb_shap_scores_y2_retrained, columns = feature_names)\n",
    "vals = np.abs(resultX.values).mean(0)\n",
    "shap_importance_retrained_nb_y2 = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance_retrained_nb_y2.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance_retrained_nb_y2['Rank'] = len(stats.rankdata(shap_importance_retrained_nb_y2['feature_importance_vals'])) \\\n",
    "    - stats.rankdata(shap_importance_retrained_nb_y2['feature_importance_vals']) + 1\n",
    "\n",
    "resultX = pd.DataFrame(nb_shap_scores_y2_cv, columns = feature_names)\n",
    "vals = np.abs(resultX.values).mean(0)\n",
    "shap_importance_nb_cv_y2 = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance_nb_cv_y2.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance_nb_cv_y2['Rank'] = len(stats.rankdata(shap_importance_nb_cv_y2['feature_importance_vals'])) \\\n",
    "    - stats.rankdata(shap_importance_nb_cv_y2['feature_importance_vals']) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(nb_shap_scores_y1, columns=independent_features).to_excel(f'results/{course_name}_SHAP_scores_NB_{year_start}.xlsx')\n",
    "pd.DataFrame(nb_shap_scores_y2, columns=independent_features).to_excel(f'results/{course_name}_SHAP_scores_NB_{year_finish}.xlsx')\n",
    "pd.DataFrame(nb_shap_scores_y2_retrained, columns=independent_features).to_excel(f'results/{course_name}_SHAP_scores_NB_{year_finish}_retrained.xlsx')\n",
    "pd.DataFrame(nb_shap_scores_y2_cv, columns=independent_features).to_excel(f'results/{course_name}_SHAP_scores_NB_{year_finish}_cv.xlsx')\n",
    "pd.DataFrame({f'NB {year_start}': nb_outer_scores_y1, f'NB {year_finish}': nb_outer_scores_y2, f'NB {year_finish} retrained': nb_outer_scores_y2_retrained,\n",
    "               f'NB {year_finish} cv': nb_outer_scores_y2_cv }).to_excel(f'results/{course_name}_NB_performance.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(f'results/{course_name}_SHAP_scores_NB_{year_start}_per_fold.xlsx', engine='xlsxwriter') as writer:\n",
    "    for i in range(10):\n",
    "\n",
    "        sheet_name = f'Sheet{i+1}' \n",
    "        pd.DataFrame(nb_shaps_y1_per_fold[i]).to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "with pd.ExcelWriter(f'results/{course_name}_SHAP_scores_NB_{year_finish}_per_fold.xlsx', engine='xlsxwriter') as writer:\n",
    "    for i in range(10):\n",
    "\n",
    "        sheet_name = f'Sheet{i+1}'  \n",
    "        pd.DataFrame(nb_shaps_y2_per_fold[i]).to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "with pd.ExcelWriter(f'results/{course_name}_SHAP_scores_NB_{year_finish}_retrained_per_fold.xlsx', engine='xlsxwriter') as writer:\n",
    "    for i in range(10):\n",
    "\n",
    "        sheet_name = f'Sheet{i+1}'  \n",
    "        pd.DataFrame(nb_shaps_y2_retrained_per_fold[i]).to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "with pd.ExcelWriter(f'results/{course_name}_SHAP_scores_NB_{year_finish}_cv_per_fold.xlsx', engine='xlsxwriter') as writer:\n",
    "    for i in range(10):\n",
    "\n",
    "        sheet_name = f'Sheet{i+1}' \n",
    "        pd.DataFrame(nb_shaps_y2_cv_per_fold[i]).to_excel(writer, sheet_name=sheet_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_psi = pd.DataFrame({'Model X on data X vs. Model X on data X+1':nb_psi_scores_y1_y2, \n",
    "                        'Model X on data X vs. Model X retrained on data X+1':nb_psi_scores_y1_y2_retrained,\n",
    "                          'Model X on data X vs. Model X+1 on data X+1':nb_psi_scores_y1_y2_cv})\n",
    "nb_psi.to_excel(f'results/{course_name} {year_start} vs. {year_finish} NB PSI.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/{course_name} {year_start} NB train indices.pickle', 'wb') as handle:\n",
    "    pickle.dump(nb_ix_training_y1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'results/{course_name} {year_start} NB test indices.pickle', 'wb') as handle:\n",
    "    pickle.dump(nb_ix_test_y1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'results/{course_name} {year_finish} NB train indices.pickle', 'wb') as handle:\n",
    "    pickle.dump(nb_ix_training_y2, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'results/{course_name} {year_finish} NB test indices.pickle', 'wb') as handle:\n",
    "    pickle.dump(nb_ix_test_y2, handle, protocol=pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_outer_scores_y1, rf_shap_scores_y1, rf_outer_scores_y2, rf_shap_scores_y2, rf_outer_scores_y2_retrained, \\\n",
    "      rf_shap_scores_y2_retrained, rf_outer_scores_y2_cv, rf_shap_scores_y2_cv, rf_ix_training_y1, rf_ix_test_y1, \\\n",
    "          rf_ix_training_y2, rf_ix_test_y2, rf_shaps_y1_per_fold, rf_shaps_y2_per_fold,\\\n",
    "          rf_shaps_y2_retrained_per_fold, rf_shaps_y2_cv_per_fold,\\\n",
    "            rf_psi_scores_y1_y2,\\\n",
    "              rf_psi_scores_y1_y2_retrained, rf_psi_scores_y1_y2_cv = run_models(RandomForestClassifier(random_state = 0), 'RF',\n",
    "                                                                                    [{'max_depth': [3, 5, 10, None], \n",
    "                                                                                      'min_samples_split': [2, 5, 10],\n",
    "                                                                                        'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "                                                                                    'max_features': ['sqrt','log2', None],\n",
    "                                                                                        'n_estimators': [50, 100, 200], \n",
    "                                                                                        'max_samples': [int(X_y1.shape[0]/2) ,X_y1.shape[0]]}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = independent_features\n",
    "\n",
    "resultX = pd.DataFrame(rf_shap_scores_y1, columns = feature_names)\n",
    "vals = np.abs(resultX.values).mean(0)\n",
    "shap_importance_rf = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance_rf.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance_rf['Rank'] = len(stats.rankdata(shap_importance_rf['feature_importance_vals'])) \\\n",
    "    - stats.rankdata(shap_importance_rf['feature_importance_vals']) + 1\n",
    "\n",
    "resultX = pd.DataFrame(rf_shap_scores_y2, columns = feature_names)\n",
    "vals = np.abs(resultX.values).mean(0)\n",
    "shap_importance_rf_y2 = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance_rf_y2.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance_rf_y2['Rank'] = len(stats.rankdata(shap_importance_rf_y2['feature_importance_vals'])) \\\n",
    "      - stats.rankdata(shap_importance_rf_y2['feature_importance_vals']) + 1\n",
    "\n",
    "resultX = pd.DataFrame(rf_shap_scores_y2_retrained, columns = feature_names)\n",
    "vals = np.abs(resultX.values).mean(0)\n",
    "shap_importance_retrained_rf_y2 = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance_retrained_rf_y2.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance_retrained_rf_y2['Rank'] = len(stats.rankdata(shap_importance_retrained_rf_y2['feature_importance_vals'])) \\\n",
    "      - stats.rankdata(shap_importance_retrained_rf_y2['feature_importance_vals']) + 1\n",
    "\n",
    "resultX = pd.DataFrame(rf_shap_scores_y2_cv, columns = feature_names)\n",
    "vals = np.abs(resultX.values).mean(0)\n",
    "shap_importance_rf_cv_y2 = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance_rf_cv_y2.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance_rf_cv_y2['Rank'] = len(stats.rankdata(shap_importance_rf_cv_y2['feature_importance_vals'])) \\\n",
    "      - stats.rankdata(shap_importance_rf_cv_y2['feature_importance_vals']) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rf_shap_scores_y1, columns=independent_features).to_excel(f'results/{course_name}_SHAP_scores_RF_{year_start}.xlsx')\n",
    "pd.DataFrame(rf_shap_scores_y2, columns=independent_features).to_excel(f'results/{course_name}_SHAP_scores_RF_{year_finish}.xlsx')\n",
    "pd.DataFrame(rf_shap_scores_y2_retrained, columns=independent_features).to_excel(f'results/{course_name}_SHAP_scores_RF_{year_finish}_retrained.xlsx')\n",
    "pd.DataFrame(rf_shap_scores_y2_cv, columns=independent_features).to_excel(f'results/{course_name}_SHAP_scores_RF_{year_finish}_cvd.xlsx')\n",
    "pd.DataFrame({f'RF {year_start}': rf_outer_scores_y1, f'RF {year_finish}': rf_outer_scores_y2, f'RF {year_finish} retrained': rf_outer_scores_y2_retrained,\n",
    "               f'RF {year_finish} cv': rf_outer_scores_y2_cv }).to_excel(f'results/{course_name}_RF_performance.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(f'results/{course_name}_SHAP_scores_RF_{year_start}_per_fold.xlsx', engine='xlsxwriter') as writer:\n",
    "    for i in range(10):\n",
    "\n",
    "        sheet_name = f'Sheet{i+1}' \n",
    "        pd.DataFrame(rf_shaps_y1_per_fold[i]).to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "with pd.ExcelWriter(f'results/{course_name}_SHAP_scores_RF_{year_finish}_per_fold.xlsx', engine='xlsxwriter') as writer:\n",
    "    for i in range(10):\n",
    "\n",
    "        sheet_name = f'Sheet{i+1}'  \n",
    "        pd.DataFrame(rf_shaps_y2_per_fold[i]).to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "with pd.ExcelWriter(f'results/{course_name}_SHAP_scores_RF_{year_finish}_retrained_per_fold.xlsx', engine='xlsxwriter') as writer:\n",
    "    for i in range(10):\n",
    "\n",
    "        sheet_name = f'Sheet{i+1}'  \n",
    "        pd.DataFrame(rf_shaps_y2_retrained_per_fold[i]).to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "with pd.ExcelWriter(f'results/{course_name}_SHAP_scores_RF_{year_finish}_cv_per_fold.xlsx', engine='xlsxwriter') as writer:\n",
    "    for i in range(10):\n",
    "\n",
    "        sheet_name = f'Sheet{i+1}' \n",
    "        pd.DataFrame(rf_shaps_y2_cv_per_fold[i]).to_excel(writer, sheet_name=sheet_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_psi = pd.DataFrame({'Model X on data X vs. Model X on data X+1':rf_psi_scores_y1_y2, \n",
    "                        'Model X on data X vs. Model X retrained on data X+1':rf_psi_scores_y1_y2_retrained,\n",
    "                          'Model X on data X vs. Model X+1 on data X+1':rf_psi_scores_y1_y2_cv})\n",
    "rf_psi.to_excel(f'results/{course_name} {year_start} vs. {year_finish} RF PSI.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/{course_name} {year_start} RF train indices.pickle', 'wb') as handle:\n",
    "    pickle.dump(rf_ix_training_y1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'results/{course_name} {year_start} RF test indices.pickle', 'wb') as handle:\n",
    "    pickle.dump(rf_ix_test_y1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'results/{course_name} {year_finish} RF train indices.pickle', 'wb') as handle:\n",
    "    pickle.dump(rf_ix_training_y2, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'results/{course_name} {year_finish} RF test indices.pickle', 'wb') as handle:\n",
    "    pickle.dump(rf_ix_test_y2, handle, protocol=pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_outer_scores_y1, lr_shap_scores_y1, lr_outer_scores_y2, lr_shap_scores_y2, lr_outer_scores_y2_retrained, \\\n",
    "    lr_shap_scores_y2_retrained, lr_outer_scores_y2_cv, lr_shap_scores_y2_cv, lr_ix_training_y1, lr_ix_test_y1, \\\n",
    "        lr_ix_training_y2, lr_ix_test_y2, lr_shaps_y1_per_fold, lr_shaps_y2_per_fold,\\\n",
    "          lr_shaps_y2_retrained_per_fold, lr_shaps_y2_cv_per_fold,\\\n",
    "            lr_psi_scores_y1_y2,\\\n",
    "              lr_psi_scores_y1_y2_retrained, lr_psi_scores_y1_y2_cv = run_models(LogisticRegression(random_state = 0), 'LR', [{ 'penalty' : ['l1','l2'], \n",
    "                                                                                    'C'       : np.logspace(-3,3,7),\n",
    "                                                                                    'solver'  : ['newton-cg', 'lbfgs', 'liblinear']}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = independent_features\n",
    "\n",
    "resultX = pd.DataFrame(lr_shap_scores_y1, columns = feature_names)\n",
    "vals = np.abs(resultX.values).mean(0)\n",
    "shap_importance_lr = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance_lr.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance_lr['Rank'] = len(stats.rankdata(shap_importance_lr['feature_importance_vals'])) \\\n",
    "    - stats.rankdata(shap_importance_lr['feature_importance_vals']) + 1\n",
    "\n",
    "resultX = pd.DataFrame(lr_shap_scores_y2, columns = feature_names)\n",
    "vals = np.abs(resultX.values).mean(0)\n",
    "shap_importance_lr_y2 = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance_lr_y2.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance_lr_y2['Rank'] = len(stats.rankdata(shap_importance_lr_y2['feature_importance_vals'])) \\\n",
    "      - stats.rankdata(shap_importance_lr_y2['feature_importance_vals']) + 1\n",
    "\n",
    "resultX = pd.DataFrame(lr_shap_scores_y2_retrained, columns = feature_names)\n",
    "vals = np.abs(resultX.values).mean(0)\n",
    "shap_importance_retrained_lr_y2 = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance_retrained_lr_y2.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance_retrained_lr_y2['Rank'] = len(stats.rankdata(shap_importance_retrained_lr_y2['feature_importance_vals'])) \\\n",
    "    - stats.rankdata(shap_importance_retrained_lr_y2['feature_importance_vals']) + 1\n",
    "\n",
    "resultX = pd.DataFrame(lr_shap_scores_y2_cv, columns = feature_names)\n",
    "vals = np.abs(resultX.values).mean(0)\n",
    "shap_importance_lr_cv_y2 = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance_lr_cv_y2.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)                   \n",
    "shap_importance_lr_cv_y2['Rank'] = len(stats.rankdata(shap_importance_lr_cv_y2['feature_importance_vals'])) \\\n",
    "    - stats.rankdata(shap_importance_lr_cv_y2['feature_importance_vals']) + 1         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(lr_shap_scores_y1, columns=independent_features).to_excel(f'results/{course_name}_SHAP_scores_LR_{year_start}.xlsx')\n",
    "pd.DataFrame(lr_shap_scores_y2, columns=independent_features).to_excel(f'results/{course_name}_SHAP_scores_LR_{year_finish}.xlsx')\n",
    "pd.DataFrame(lr_shap_scores_y2_retrained, columns=independent_features).to_excel(f'results/{course_name}_SHAP_scores_LR_{year_finish}_retrained.xlsx')\n",
    "pd.DataFrame(lr_shap_scores_y2_cv, columns=independent_features).to_excel(f'results/{course_name}_SHAP_scores_LR_{year_finish}_cvd.xlsx')\n",
    "pd.DataFrame({f'LR {year_start}': lr_outer_scores_y1, f'LR {year_finish}': lr_outer_scores_y2, f'LR {year_finish} retrained': lr_outer_scores_y2_retrained,\n",
    "               f'LR {year_finish} cv': lr_outer_scores_y2_cv }).to_excel(f'results/{course_name}_LR_performance.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(f'results/{course_name}_SHAP_scores_LR_{year_start}_per_fold.xlsx', engine='xlsxwriter') as writer:\n",
    "    for i in range(10):\n",
    "\n",
    "        sheet_name = f'Sheet{i+1}' \n",
    "        pd.DataFrame(lr_shaps_y1_per_fold[i]).to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "with pd.ExcelWriter(f'results/{course_name}_SHAP_scores_LR_{year_finish}_per_fold.xlsx', engine='xlsxwriter') as writer:\n",
    "    for i in range(10):\n",
    "\n",
    "        sheet_name = f'Sheet{i+1}'  \n",
    "        pd.DataFrame(lr_shaps_y2_per_fold[i]).to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "with pd.ExcelWriter(f'results/{course_name}_SHAP_scores_LR_{year_finish}_retrained_per_fold.xlsx', engine='xlsxwriter') as writer:\n",
    "    for i in range(10):\n",
    "\n",
    "        sheet_name = f'Sheet{i+1}'  \n",
    "        pd.DataFrame(lr_shaps_y2_retrained_per_fold[i]).to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "with pd.ExcelWriter(f'results/{course_name}_SHAP_scores_LR_{year_finish}_cv_per_fold.xlsx', engine='xlsxwriter') as writer:\n",
    "    for i in range(10):\n",
    "\n",
    "        sheet_name = f'Sheet{i+1}' \n",
    "        pd.DataFrame(lr_shaps_y2_cv_per_fold[i]).to_excel(writer, sheet_name=sheet_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_psi = pd.DataFrame({'Model X on data X vs. Model X on data X+1':lr_psi_scores_y1_y2, \n",
    "                        'Model X on data X vs. Model X retrained on data X+1':lr_psi_scores_y1_y2_retrained,\n",
    "                          'Model X on data X vs. Model X+1 on data X+1':lr_psi_scores_y1_y2_cv})\n",
    "lr_psi.to_excel(f'results/{course_name} {year_start} vs. {year_finish} LR PSI.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/{course_name} {year_start} LR train indices.pickle', 'wb') as handle:\n",
    "    pickle.dump(lr_ix_training_y1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'results/{course_name} {year_start} LR test indices.pickle', 'wb') as handle:\n",
    "    pickle.dump(lr_ix_test_y1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'results/{course_name} {year_finish} LR train indices.pickle', 'wb') as handle:\n",
    "    pickle.dump(lr_ix_training_y2, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'results/{course_name} {year_finish} LR test indices.pickle', 'wb') as handle:\n",
    "    pickle.dump(lr_ix_test_y2, handle, protocol=pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_outer_scores_y1, svm_shap_scores_y1, svm_outer_scores_y2, svm_shap_scores_y2, svm_outer_scores_y2_retrained, \\\n",
    "      svm_shap_scores_y2_retrained, svm_outer_scores_y2_cv, svm_shap_scores_y2_cv, svm_ix_training_y1, svm_ix_test_y1, \\\n",
    "          svm_ix_training_y2, svm_ix_test_y2, svm_shaps_y1_per_fold, svm_shaps_y2_per_fold,\\\n",
    "          svm_shaps_y2_retrained_per_fold, svm_shaps_y2_cv_per_fold,\\\n",
    "            svm_psi_scores_y1_y2,\\\n",
    "              svm_psi_scores_y1_y2_retrained, svm_psi_scores_y1_y2_cv = run_models_scaled(svm.SVC(probability=True), 'SVM', [{'C': [0.1, 1, 10, 100], \n",
    "                                                                                                    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "                                                                                                    'kernel': ['rbf', 'poly', 'sigmoid']}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = independent_features\n",
    "\n",
    "resultX = pd.DataFrame(svm_shap_scores_y1, columns = feature_names)\n",
    "vals = np.abs(resultX.values).mean(0)\n",
    "shap_importance_svm = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance_svm.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance_svm['Rank'] = len(stats.rankdata(shap_importance_svm['feature_importance_vals'])) \\\n",
    "      - stats.rankdata(shap_importance_svm['feature_importance_vals']) + 1\n",
    "\n",
    "resultX = pd.DataFrame(svm_shap_scores_y2, columns = feature_names)\n",
    "vals = np.abs(resultX.values).mean(0)\n",
    "shap_importance_svm_y2 = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance_svm_y2.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance_svm_y2['Rank'] = len(stats.rankdata(shap_importance_svm_y2['feature_importance_vals'])) \\\n",
    "    - stats.rankdata(shap_importance_svm_y2['feature_importance_vals']) + 1\n",
    "\n",
    "resultX = pd.DataFrame(svm_shap_scores_y2_retrained, columns = feature_names)\n",
    "vals = np.abs(resultX.values).mean(0)\n",
    "shap_importance_retrained_svm_y2 = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance_retrained_svm_y2.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance_retrained_svm_y2['Rank'] = len(stats.rankdata(shap_importance_retrained_svm_y2['feature_importance_vals'])) \\\n",
    "    - stats.rankdata(shap_importance_retrained_svm_y2['feature_importance_vals']) + 1\n",
    "\n",
    "resultX = pd.DataFrame(svm_shap_scores_y2_cv, columns = feature_names)\n",
    "vals = np.abs(resultX.values).mean(0)\n",
    "shap_importance_svm_cv_y2 = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance_svm_cv_y2.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance_svm_cv_y2['Rank'] = len(stats.rankdata(shap_importance_svm_cv_y2['feature_importance_vals'])) \\\n",
    "      - stats.rankdata(shap_importance_svm_cv_y2['feature_importance_vals']) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(svm_shap_scores_y1, columns=independent_features).to_excel(f'results/{course_name}_SHAP_scores_SVM_{year_start}.xlsx')\n",
    "pd.DataFrame(svm_shap_scores_y2, columns=independent_features).to_excel(f'results/{course_name}_SHAP_scores_SVM_{year_finish}.xlsx')\n",
    "pd.DataFrame(svm_shap_scores_y2_retrained, columns=independent_features).to_excel(f'results/{course_name}_SHAP_scores_SVM_{year_finish}_retrained.xlsx')\n",
    "pd.DataFrame(svm_shap_scores_y2_cv, columns=independent_features).to_excel(f'results/{course_name}_SHAP_scores_SVM_{year_finish}_cv.xlsx')\n",
    "pd.DataFrame({f'SVM {year_start}': svm_outer_scores_y1, f'SVM {year_finish}': svm_outer_scores_y2, \n",
    "              f'SVM {year_finish} retrained': svm_outer_scores_y2_retrained,\n",
    "                f'SVM {year_finish} cv': svm_outer_scores_y2_cv }).to_excel(f'results/{course_name}_SVM_performance.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(f'results/{course_name}_SHAP_scores_SVM_{year_start}_per_fold.xlsx', engine='xlsxwriter') as writer:\n",
    "    for i in range(10):\n",
    "\n",
    "        sheet_name = f'Sheet{i+1}' \n",
    "        pd.DataFrame(svm_shaps_y1_per_fold[i]).to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "with pd.ExcelWriter(f'results/{course_name}_SHAP_scores_SVM_{year_finish}_per_fold.xlsx', engine='xlsxwriter') as writer:\n",
    "    for i in range(10):\n",
    "\n",
    "        sheet_name = f'Sheet{i+1}'  \n",
    "        pd.DataFrame(svm_shaps_y2_per_fold[i]).to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "with pd.ExcelWriter(f'results/{course_name}_SHAP_scores_SVM_{year_finish}_retrained_per_fold.xlsx', engine='xlsxwriter') as writer:\n",
    "    for i in range(10):\n",
    "\n",
    "        sheet_name = f'Sheet{i+1}'  \n",
    "        pd.DataFrame(svm_shaps_y2_retrained_per_fold[i]).to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "with pd.ExcelWriter(f'results/{course_name}_SHAP_scores_SVM_{year_finish}_cv_per_fold.xlsx', engine='xlsxwriter') as writer:\n",
    "    for i in range(10):\n",
    "\n",
    "        sheet_name = f'Sheet{i+1}' \n",
    "        pd.DataFrame(svm_shaps_y2_cv_per_fold[i]).to_excel(writer, sheet_name=sheet_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_psi = pd.DataFrame({'Model X on data X vs. Model X on data X+1':svm_psi_scores_y1_y2, \n",
    "                        'Model X on data X vs. Model X retrained on data X+1':svm_psi_scores_y1_y2_retrained,\n",
    "                          'Model X on data X vs. Model X+1 on data X+1':svm_psi_scores_y1_y2_cv})\n",
    "svm_psi.to_excel(f'results/{course_name} {year_start} vs. {year_finish} SVM PSI.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/{course_name} {year_start} SVM train indices.pickle', 'wb') as handle:\n",
    "    pickle.dump(svm_ix_training_y1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'results/{course_name} {year_start} SVM test indices.pickle', 'wb') as handle:\n",
    "    pickle.dump(svm_ix_test_y1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'results/{course_name} {year_finish} SVM train indices.pickle', 'wb') as handle:\n",
    "    pickle.dump(svm_ix_training_y2, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'results/{course_name} {year_finish} SVM test indices.pickle', 'wb') as handle:\n",
    "    pickle.dump(svm_ix_test_y2, handle, protocol=pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_outer_scores_y1, knn_shap_scores_y1, knn_outer_scores_y2, knn_shap_scores_y2, knn_outer_scores_y2_retrained,\\\n",
    "      knn_shap_scores_y2_retrained, knn_outer_scores_y2_cv, knn_shap_scores_y2_cv, knn_ix_training_y1, knn_ix_test_y1,\\\n",
    "          knn_ix_training_y2, knn_ix_test_y2, knn_shaps_y1_per_fold, knn_shaps_y2_per_fold,\\\n",
    "          knn_shaps_y2_retrained_per_fold, knn_shaps_y2_cv_per_fold,\\\n",
    "            knn_psi_scores_y1_y2,\\\n",
    "              knn_psi_scores_y1_y2_retrained, knn_psi_scores_y1_y2_cv = run_models_scaled(neighbors.KNeighborsClassifier(), 'KNN', [{'n_neighbors': range(1,30, 5), \n",
    "                                                                                                        'weights': ['uniform', 'distance']}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = independent_features\n",
    "\n",
    "resultX = pd.DataFrame(knn_shap_scores_y1, columns = feature_names)\n",
    "vals = np.abs(resultX.values).mean(0)\n",
    "shap_importance_knn = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance_knn.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance_knn['Rank'] = len(stats.rankdata(shap_importance_knn['feature_importance_vals'])) \\\n",
    "    - stats.rankdata(shap_importance_knn['feature_importance_vals']) + 1\n",
    "\n",
    "resultX = pd.DataFrame(knn_shap_scores_y2, columns = feature_names)\n",
    "vals = np.abs(resultX.values).mean(0)\n",
    "shap_importance_knn_y2 = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance_knn_y2.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance_knn_y2['Rank'] = len(stats.rankdata(shap_importance_knn_y2['feature_importance_vals'])) \\\n",
    "      - stats.rankdata(shap_importance_knn_y2['feature_importance_vals']) + 1\n",
    "\n",
    "resultX = pd.DataFrame(knn_shap_scores_y2_retrained, columns = feature_names)\n",
    "vals = np.abs(resultX.values).mean(0)\n",
    "shap_importance_retrained_knn_y2 = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance_retrained_knn_y2.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance_retrained_knn_y2['Rank'] = len(stats.rankdata(shap_importance_retrained_knn_y2['feature_importance_vals'])) \\\n",
    "      - stats.rankdata(shap_importance_retrained_knn_y2['feature_importance_vals']) + 1\n",
    "\n",
    "resultX = pd.DataFrame(knn_shap_scores_y2_cv, columns = feature_names)\n",
    "vals = np.abs(resultX.values).mean(0)\n",
    "shap_importance_knn_cv_y2 = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance_knn_cv_y2.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance_knn_cv_y2['Rank'] = len(stats.rankdata(shap_importance_knn_cv_y2['feature_importance_vals'])) \\\n",
    "    - stats.rankdata(shap_importance_knn_cv_y2['feature_importance_vals']) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(knn_shap_scores_y1, columns=independent_features).to_excel(f'results/{course_name}_SHAP_scores_KNN_{year_start}.xlsx')\n",
    "pd.DataFrame(knn_shap_scores_y2, columns=independent_features).to_excel(f'results/{course_name}_SHAP_scores_KNN_{year_finish}.xlsx')\n",
    "pd.DataFrame(knn_shap_scores_y2_retrained, columns=independent_features).to_excel(f'results/{course_name}_SHAP_scores_KNN_{year_finish}_retrained.xlsx')\n",
    "pd.DataFrame(knn_shap_scores_y2_cv, columns=independent_features).to_excel(f'results/{course_name}_SHAP_scores_KNN_{year_finish}_cv.xlsx')\n",
    "pd.DataFrame({f'KNN {year_start}': knn_outer_scores_y1, f'KNN {year_finish}': knn_outer_scores_y2, \n",
    "              f'KNN {year_finish} retrained': knn_outer_scores_y2_retrained,\n",
    "                f'KNN {year_finish} cv': knn_outer_scores_y2_cv }).to_excel(f'results/{course_name}_KNN_performance.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(f'results/{course_name}_SHAP_scores_KNN_{year_start}_per_fold.xlsx', engine='xlsxwriter') as writer:\n",
    "    for i in range(10):\n",
    "\n",
    "        sheet_name = f'Sheet{i+1}' \n",
    "        pd.DataFrame(knn_shaps_y1_per_fold[i]).to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "with pd.ExcelWriter(f'results/{course_name}_SHAP_scores_KNN_{year_finish}_per_fold.xlsx', engine='xlsxwriter') as writer:\n",
    "    for i in range(10):\n",
    "\n",
    "        sheet_name = f'Sheet{i+1}'  \n",
    "        pd.DataFrame(knn_shaps_y2_per_fold[i]).to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "with pd.ExcelWriter(f'results/{course_name}_SHAP_scores_KNN_{year_finish}_retrained_per_fold.xlsx', engine='xlsxwriter') as writer:\n",
    "    for i in range(10):\n",
    "\n",
    "        sheet_name = f'Sheet{i+1}'  \n",
    "        pd.DataFrame(knn_shaps_y2_retrained_per_fold[i]).to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "with pd.ExcelWriter(f'results/{course_name}_SHAP_scores_KNN_{year_finish}_cv_per_fold.xlsx', engine='xlsxwriter') as writer:\n",
    "    for i in range(10):\n",
    "\n",
    "        sheet_name = f'Sheet{i+1}' \n",
    "        pd.DataFrame(knn_shaps_y2_cv_per_fold[i]).to_excel(writer, sheet_name=sheet_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_psi = pd.DataFrame({'Model X on data X vs. Model X on data X+1':knn_psi_scores_y1_y2, \n",
    "                        'Model X on data X vs. Model X retrained on data X+1':knn_psi_scores_y1_y2_retrained,\n",
    "                          'Model X on data X vs. Model X+1 on data X+1':knn_psi_scores_y1_y2_cv})\n",
    "knn_psi.to_excel(f'results/{course_name} {year_start} vs. {year_finish} KNN PSI.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/{course_name} {year_start} KNN train indices.pickle', 'wb') as handle:\n",
    "    pickle.dump(knn_ix_training_y1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'results/{course_name} {year_start} KNN test indices.pickle', 'wb') as handle:\n",
    "    pickle.dump(knn_ix_test_y1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'results/{course_name} {year_finish} KNN train indices.pickle', 'wb') as handle:\n",
    "    pickle.dump(knn_ix_training_y2, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'results/{course_name} {year_finish} KNN test indices.pickle', 'wb') as handle:\n",
    "    pickle.dump(knn_ix_test_y2, handle, protocol=pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_outer_scores_y1, mlp_shap_scores_y1, mlp_outer_scores_y2, mlp_shap_scores_y2, mlp_outer_scores_y2_retrained,\\\n",
    "      mlp_shap_scores_y2_retrained, mlp_outer_scores_y2_cv, mlp_shap_scores_y2_cv, mlp_ix_training_y1, mlp_ix_test_y1,\\\n",
    "          mlp_ix_training_y2, mlp_ix_test_y2, mlp_shaps_y1_per_fold, mlp_shaps_y2_per_fold,\\\n",
    "          mlp_shaps_y2_retrained_per_fold, mlp_shaps_y2_cv_per_fold,\\\n",
    "            mlp_psi_scores_y1_y2,\\\n",
    "              mlp_psi_scores_y1_y2_retrained, mlp_psi_scores_y1_y2_cv = run_models_scaled(MLPClassifier(batch_size='auto', warm_start=True, max_iter=400), 'MLP', [{\n",
    "    'hidden_layer_sizes': [(int(len(X_y1)/2),), (int(len(X_y1)/2), int(len(X_y1)/2/2),)],\n",
    "    'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'alpha': [0.000001, 0.00001, 0.0001],\n",
    "    'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "    'learning_rate_init':[0.001, 0.0001]}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = independent_features\n",
    "\n",
    "resultX = pd.DataFrame(mlp_shap_scores_y1, columns = feature_names)\n",
    "vals = np.abs(resultX.values).mean(0)\n",
    "shap_importance_mlp = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance_mlp.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance_mlp['Rank'] = len(stats.rankdata(shap_importance_mlp['feature_importance_vals'])) \\\n",
    "    - stats.rankdata(shap_importance_mlp['feature_importance_vals']) + 1\n",
    "\n",
    "resultX = pd.DataFrame(mlp_shap_scores_y2, columns = feature_names)\n",
    "vals = np.abs(resultX.values).mean(0)\n",
    "shap_importance_mlp_y2 = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance_mlp_y2.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance_mlp_y2['Rank'] = len(stats.rankdata(shap_importance_mlp_y2['feature_importance_vals'])) \\\n",
    "    - stats.rankdata(shap_importance_mlp_y2['feature_importance_vals']) + 1\n",
    "\n",
    "resultX = pd.DataFrame(mlp_shap_scores_y2_retrained, columns = feature_names)\n",
    "vals = np.abs(resultX.values).mean(0)\n",
    "shap_importance_retrained_mlp_y2 = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance_retrained_mlp_y2.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance_retrained_mlp_y2['Rank'] = len(stats.rankdata(shap_importance_retrained_mlp_y2['feature_importance_vals'])) \\\n",
    "      - stats.rankdata(shap_importance_retrained_mlp_y2['feature_importance_vals']) + 1\n",
    "\n",
    "resultX = pd.DataFrame(mlp_shap_scores_y2_cv, columns = feature_names)\n",
    "vals = np.abs(resultX.values).mean(0)\n",
    "shap_importance_mlp_cv_y2 = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance_mlp_cv_y2.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance_mlp_cv_y2['Rank'] = len(stats.rankdata(shap_importance_mlp_cv_y2['feature_importance_vals'])) \\\n",
    "    - stats.rankdata(shap_importance_mlp_cv_y2['feature_importance_vals']) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(mlp_shap_scores_y1, columns=independent_features).to_excel(f'results/{course_name}_SHAP_scores_MLP_{year_start}.xlsx')\n",
    "pd.DataFrame(mlp_shap_scores_y2, columns=independent_features).to_excel(f'results/{course_name}_SHAP_scores_MLP_{year_finish}.xlsx')\n",
    "pd.DataFrame(mlp_shap_scores_y2_retrained, columns=independent_features).to_excel(f'results/{course_name}_SHAP_scores_MLP_{year_finish}_retrained.xlsx')\n",
    "pd.DataFrame(mlp_shap_scores_y2_cv, columns=independent_features).to_excel(f'results/{course_name}_SHAP_scores_MLP_{year_finish}_cv.xlsx')\n",
    "pd.DataFrame({f'MLP {year_start}': mlp_outer_scores_y1, f'MLP {year_finish}': mlp_outer_scores_y2, \n",
    "              f'MLP {year_finish} retrained': mlp_outer_scores_y2_retrained,\n",
    "                f'MLP {year_finish} cv': mlp_outer_scores_y2_cv }).to_excel(f'results/{course_name}_MLP_performance.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(f'results/{course_name}_SHAP_scores_MLP_{year_start}_per_fold.xlsx', engine='xlsxwriter') as writer:\n",
    "    for i in range(10):\n",
    "\n",
    "        sheet_name = f'Sheet{i+1}' \n",
    "        pd.DataFrame(mlp_shaps_y1_per_fold[i]).to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "with pd.ExcelWriter(f'results/{course_name}_SHAP_scores_MLP_{year_finish}_per_fold.xlsx', engine='xlsxwriter') as writer:\n",
    "    for i in range(10):\n",
    "\n",
    "        sheet_name = f'Sheet{i+1}'  \n",
    "        pd.DataFrame(mlp_shaps_y2_per_fold[i]).to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "with pd.ExcelWriter(f'results/{course_name}_SHAP_scores_MLP_{year_finish}_retrained_per_fold.xlsx', engine='xlsxwriter') as writer:\n",
    "    for i in range(10):\n",
    "\n",
    "        sheet_name = f'Sheet{i+1}'  \n",
    "        pd.DataFrame(mlp_shaps_y2_retrained_per_fold[i]).to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "with pd.ExcelWriter(f'results/{course_name}_SHAP_scores_MLP_{year_finish}_cv_per_fold.xlsx', engine='xlsxwriter') as writer:\n",
    "    for i in range(10):\n",
    "\n",
    "        sheet_name = f'Sheet{i+1}' \n",
    "        pd.DataFrame(mlp_shaps_y2_cv_per_fold[i]).to_excel(writer, sheet_name=sheet_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_psi = pd.DataFrame({'Model X on data X vs. Model X on data X+1':mlp_psi_scores_y1_y2, \n",
    "                        'Model X on data X vs. Model X retrained on data X+1':mlp_psi_scores_y1_y2_retrained,\n",
    "                          'Model X on data X vs. Model X+1 on data X+1':mlp_psi_scores_y1_y2_cv})\n",
    "mlp_psi.to_excel(f'results/{course_name} {year_start} vs. {year_finish} MLP PSI.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/{course_name} {year_start} MLP train indices.pickle', 'wb') as handle:\n",
    "    pickle.dump(mlp_ix_training_y1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'results/{course_name} {year_start} MLP test indices.pickle', 'wb') as handle:\n",
    "    pickle.dump(mlp_ix_test_y1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'results/{course_name} {year_finish} MLP train indices.pickle', 'wb') as handle:\n",
    "    pickle.dump(mlp_ix_training_y2, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'results/{course_name} {year_finish} MLP test indices.pickle', 'wb') as handle:\n",
    "    pickle.dump(mlp_ix_test_y2, handle, protocol=pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_outer_scores_y1, xgb_shap_scores_y1, xgb_outer_scores_y2, xgb_shap_scores_y2, xgb_outer_scores_y2_retrained,\\\n",
    "      xgb_shap_scores_y2_retrained, xgb_outer_scores_y2_cv, xgb_shap_scores_y2_cv, xgb_ix_training_y1, xgb_ix_test_y1,\\\n",
    "          xgb_ix_training_y2, xgb_ix_test_y2, xgb_shaps_y1_per_fold, xgb_shaps_y2_per_fold,\\\n",
    "          xgb_shaps_y2_retrained_per_fold, xgb_shaps_y2_cv_per_fold,\\\n",
    "            xgb_psi_scores_y1_y2,\\\n",
    "              xgb_psi_scores_y1_y2_retrained, xgb_psi_scores_y1_y2_cv = run_models_scaled(GradientBoostingClassifier(), 'XGB', \n",
    "                                                                                        [{\n",
    "                                                                                          'learning_rate':[0.1,0.01],\n",
    "                                                                                          'n_estimators': [50, 100, 200],\n",
    "                                                                                          'min_samples_split': [2, 5, 10],\n",
    "                                                                                          'max_depth': [3, 5, 10, None], \n",
    "                                                                                          'max_features': ['sqrt','log2', None]}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = independent_features\n",
    "\n",
    "resultX = pd.DataFrame(xgb_shap_scores_y1, columns = feature_names)\n",
    "vals = np.abs(resultX.values).mean(0)\n",
    "shap_importance_xgb = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance_xgb.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance_xgb['Rank'] = len(stats.rankdata(shap_importance_xgb['feature_importance_vals'])) \\\n",
    "    - stats.rankdata(shap_importance_xgb['feature_importance_vals']) + 1\n",
    "\n",
    "resultX = pd.DataFrame(xgb_shap_scores_y2, columns = feature_names)\n",
    "vals = np.abs(resultX.values).mean(0)\n",
    "shap_importance_xgb_y2 = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance_xgb_y2.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance_xgb_y2['Rank'] = len(stats.rankdata(shap_importance_xgb_y2['feature_importance_vals'])) \\\n",
    "    - stats.rankdata(shap_importance_xgb_y2['feature_importance_vals']) + 1\n",
    "\n",
    "resultX = pd.DataFrame(xgb_shap_scores_y2_retrained, columns = feature_names)\n",
    "vals = np.abs(resultX.values).mean(0)\n",
    "shap_importance_retrained_xgb_y2 = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance_retrained_xgb_y2.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance_retrained_xgb_y2['Rank'] = len(stats.rankdata(shap_importance_retrained_xgb_y2['feature_importance_vals'])) \\\n",
    "      - stats.rankdata(shap_importance_retrained_xgb_y2['feature_importance_vals']) + 1\n",
    "\n",
    "resultX = pd.DataFrame(xgb_shap_scores_y2_cv, columns = feature_names)\n",
    "vals = np.abs(resultX.values).mean(0)\n",
    "shap_importance_xgb_cv_y2 = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance_xgb_cv_y2.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance_xgb_cv_y2['Rank'] = len(stats.rankdata(shap_importance_xgb_cv_y2['feature_importance_vals'])) \\\n",
    "    - stats.rankdata(shap_importance_xgb_cv_y2['feature_importance_vals']) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(xgb_shap_scores_y1, columns=independent_features).to_excel(f'results/{course_name}_SHAP_scores_XGB_{year_start}.xlsx')\n",
    "pd.DataFrame(xgb_shap_scores_y2, columns=independent_features).to_excel(f'results/{course_name}_SHAP_scores_XGB_{year_finish}.xlsx')\n",
    "pd.DataFrame(xgb_shap_scores_y2_retrained, columns=independent_features).to_excel(f'results/{course_name}_SHAP_scores_XGB_{year_finish}_retrained.xlsx')\n",
    "pd.DataFrame(xgb_shap_scores_y2_cv, columns=independent_features).to_excel(f'results/{course_name}_SHAP_scores_XGB_{year_finish}_cv.xlsx')\n",
    "pd.DataFrame({f'XGB {year_start}': xgb_outer_scores_y1, f'XGB {year_finish}': xgb_outer_scores_y2, \n",
    "              f'XGB {year_finish} retrained': xgb_outer_scores_y2_retrained,\n",
    "                f'XGB {year_finish} cv': xgb_outer_scores_y2_cv }).to_excel(f'results/{course_name}_XGB_performance.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(f'results/{course_name}_SHAP_scores_XGB_{year_start}_per_fold.xlsx', engine='xlsxwriter') as writer:\n",
    "    for i in range(10):\n",
    "\n",
    "        sheet_name = f'Sheet{i+1}' \n",
    "        pd.DataFrame(xgb_shaps_y1_per_fold[i]).to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "with pd.ExcelWriter(f'results/{course_name}_SHAP_scores_XGB_{year_finish}_per_fold.xlsx', engine='xlsxwriter') as writer:\n",
    "    for i in range(10):\n",
    "\n",
    "        sheet_name = f'Sheet{i+1}'  \n",
    "        pd.DataFrame(xgb_shaps_y2_per_fold[i]).to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "with pd.ExcelWriter(f'results/{course_name}_SHAP_scores_XGB_{year_finish}_retrained_per_fold.xlsx', engine='xlsxwriter') as writer:\n",
    "    for i in range(10):\n",
    "\n",
    "        sheet_name = f'Sheet{i+1}'  \n",
    "        pd.DataFrame(xgb_shaps_y2_retrained_per_fold[i]).to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "with pd.ExcelWriter(f'results/{course_name}_SHAP_scores_XGB_{year_finish}_cv_per_fold.xlsx', engine='xlsxwriter') as writer:\n",
    "    for i in range(10):\n",
    "\n",
    "        sheet_name = f'Sheet{i+1}' \n",
    "        pd.DataFrame(xgb_shaps_y2_cv_per_fold[i]).to_excel(writer, sheet_name=sheet_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_psi = pd.DataFrame({'Model X on data X vs. Model X on data X+1':xgb_psi_scores_y1_y2, \n",
    "                        'Model X on data X vs. Model X retrained on data X+1':xgb_psi_scores_y1_y2_retrained,\n",
    "                          'Model X on data X vs. Model X+1 on data X+1':xgb_psi_scores_y1_y2_cv})\n",
    "xgb_psi.to_excel(f'results/{course_name} {year_start} vs. {year_finish} XGB PSI.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/{course_name} {year_start} XGB train indices.pickle', 'wb') as handle:\n",
    "    pickle.dump(xgb_ix_training_y1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'results/{course_name} {year_start} XGB test indices.pickle', 'wb') as handle:\n",
    "    pickle.dump(xgb_ix_test_y1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'results/{course_name} {year_finish} XGB train indices.pickle', 'wb') as handle:\n",
    "    pickle.dump(xgb_ix_training_y2, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'results/{course_name} {year_finish} XGB test indices.pickle', 'wb') as handle:\n",
    "    pickle.dump(xgb_ix_test_y2, handle, protocol=pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Objective(trial, X, y):\n",
    "    n_da = trial.suggest_int(\"n_da\", 8, 32, step=8)\n",
    "    n_steps = trial.suggest_int(\"n_steps\", 1, 3, step=1)\n",
    "    gamma = trial.suggest_float(\"gamma\", 1., 1.4, step=0.2)\n",
    "    n_shared = trial.suggest_int(\"n_shared\", 1, 3)\n",
    "    lambda_sparse = trial.suggest_float(\"lambda_sparse\", 1e-6, 1e-3, log=True)\n",
    "    \n",
    "    tabnet_params = dict(n_d=n_da, n_a=n_da, n_steps=n_steps, gamma=gamma,\n",
    "                     lambda_sparse=lambda_sparse,\n",
    "                     optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n",
    "                     n_shared=n_shared,\n",
    "                     scheduler_params=dict(mode=\"min\",\n",
    "                                           patience=trial.suggest_int(\"patienceScheduler\",low=10,high=20),\n",
    "                                           min_lr=1e-5,\n",
    "                                           factor=0.5,),\n",
    "                     verbose=0,\n",
    "                     ) \n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True) \n",
    "    CV_score_array    =[]\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_valid = X[train_index], X[test_index]\n",
    "        y_train, y_valid = y[train_index], y[test_index]\n",
    "        regressor = TabNetClassifier(**tabnet_params)\n",
    "        regressor.fit(X_train=X_train, y_train=y_train.flatten(),\n",
    "                  eval_set=[(X_valid, y_valid.flatten())],\n",
    "                  patience=trial.suggest_int(\"patience\",low=15,high=30), max_epochs=trial.suggest_int('epochs', 1, 100),\n",
    "                  eval_metric=['balanced_accuracy'],\n",
    "                  batch_size=64)\n",
    "        CV_score_array.append(regressor.best_cost)\n",
    "    avg = np.mean(CV_score_array)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models_TabNet(model, model_name):\n",
    "    \n",
    "    outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "    psi_scores_y1_y2 = []\n",
    "    psi_scores_y1_y2_retrained = []\n",
    "    psi_scores_y1_y2_cv = []\n",
    "\n",
    "    outer_scores_y1 = []\n",
    "    shap_scores_y1 = []\n",
    "\n",
    "    outer_scores_y2 = []\n",
    "    shap_scores_y2 = []\n",
    "\n",
    "    outer_scores_y2_retrained = []\n",
    "    shap_scores_y2_retrained = []\n",
    "\n",
    "    outer_scores_y2_cv = []\n",
    "    shap_scores_y2_cv = []\n",
    "\n",
    "    ix_training_y1, ix_test_y1 = [], []\n",
    "    ix_training_y2, ix_test_y2 = [], []\n",
    "\n",
    "    shaps_y1_per_fold = {}\n",
    "    shaps_y2_per_fold = {}\n",
    "    shaps_y2_retrained_per_fold = {}\n",
    "    shaps_y2_cv_per_fold = {}\n",
    "\n",
    "    for fold in outer_cv.split(X_y1, y_y1):\n",
    "        ix_training_y1.append(fold[0]), ix_test_y1.append(fold[1])\n",
    "\n",
    "    for fold in outer_cv.split(X_y2, y_y2):\n",
    "        ix_training_y2.append(fold[0]), ix_test_y2.append(fold[1])\n",
    "\n",
    "    \n",
    "    for i in range(10):  \n",
    "\n",
    "        train_idX_y1, test_idX_y1 = ix_training_y1[i], ix_test_y1[i]\n",
    "        train_idX_y2, test_idX_y2 = ix_training_y2[i], ix_test_y2[i]\n",
    "        \n",
    "        # step 1)\n",
    "        study = optuna.create_study(direction=\"maximize\", study_name='TabNet optimization')\n",
    "        study.optimize(lambda trial: Objective(trial,X_y1[train_idX_y1], y_y1[train_idX_y1].flatten()), timeout=6*60) \n",
    "        TabNet_params = study.best_params\n",
    "\n",
    "        final_params = dict(n_d=TabNet_params['n_da'], n_a=TabNet_params['n_da'],\n",
    "                     n_steps=TabNet_params['n_steps'], \n",
    "                     gamma=TabNet_params['gamma'],\n",
    "                      n_shared=TabNet_params['n_shared'])\n",
    "        epochs = TabNet_params['epochs']\n",
    "\n",
    "        print(f'Step {i} for model {model_name}')\n",
    "        print('\\n        Best ACCURACY y1 model %.2f%%' % (study.best_value * 100))\n",
    "        print('        Best parameters y1 model:', study.best_params)\n",
    "\n",
    "        best_model = TabNetClassifier(**final_params)\n",
    "        best_model.fit(X_train=X_y1[train_idX_y1], y_train=y_y1[train_idX_y1].flatten(), \n",
    "                    patience=TabNet_params['patience'], max_epochs=epochs,\n",
    "                        batch_size=64,\n",
    "                    eval_metric=['balanced_accuracy'])\n",
    "        \n",
    "        # step 2) \n",
    "        y_pred = best_model.predict(X_y1[test_idX_y1])\n",
    "        outer_scores_y1.append(balanced_accuracy_score(y_y1[test_idX_y1], y_pred))\n",
    "        print('AUC y1 (on outer test fold) %.2f%%' % (outer_scores_y1[-1]*100))\n",
    "\n",
    "        # step 3) \n",
    "        explainer_y1 = shap.KernelExplainer(best_model.predict_proba, shap.sample(X_y1[train_idX_y1], 100))\n",
    "        shap_values_y1 = explainer_y1.shap_values(X_y1[test_idX_y1])\n",
    "        for SHAPs in shap_values_y1[1]:\n",
    "            shap_scores_y1.append(SHAPs)\n",
    "        shaps_y1_per_fold[i] = shap_values_y1[1]\n",
    "\n",
    "        # step 4)  \n",
    "        y_pred = best_model.predict(X_y2[test_idX_y2])\n",
    "        outer_scores_y2.append(balanced_accuracy_score(y_y2[test_idX_y2], y_pred))\n",
    "        print('ACCURACY y2 (on outer test fold) %.2f%%' % (outer_scores_y2[-1]*100))\n",
    "        probas_y1 = best_model.predict_proba(X_y1[test_idX_y1])[:,1]\n",
    "        probas_y2 = best_model.predict_proba(X_y2[test_idX_y2])[:,1]\n",
    "        psi_scores_y1_y2.append(psi(probas_y1,\n",
    "                                     probas_y2))\n",
    "        \n",
    "        # step 5)\n",
    "        shap_values_y2 = explainer_y1.shap_values(X_y2[test_idX_y2])\n",
    "        for SHAPs in shap_values_y2[1]:\n",
    "            shap_scores_y2.append(SHAPs) \n",
    "        shaps_y2_per_fold[i] = shap_values_y2[1]\n",
    "\n",
    "        # step 6)\n",
    "        best_model.fit(X_y2[train_idX_y2], y_y2[train_idX_y2].flatten(),\n",
    "                       patience=TabNet_params['patience'], max_epochs=epochs,\n",
    "                        batch_size=64,\n",
    "                    eval_metric=['balanced_accuracy'])\n",
    "\n",
    "        # step 7)\n",
    "        y_pred = best_model.predict(X_y2[test_idX_y2])\n",
    "        outer_scores_y2_retrained.append(balanced_accuracy_score(y_y2[test_idX_y2], y_pred))\n",
    "        print('ACCURACY y2 retrained (on outer test fold) %.2f%%' % (outer_scores_y2_retrained[-1]*100))\n",
    "        probas_y2_retrained = best_model.predict_proba(X_y2[test_idX_y2])[:,1]\n",
    "        psi_scores_y1_y2_retrained.append(psi(probas_y1,\n",
    "                                               probas_y2_retrained))\n",
    "\n",
    "        # step 8)\n",
    "        explainer_y2_retrained = shap.KernelExplainer(best_model.predict_proba, shap.sample(X_y2[train_idX_y2], 100))\n",
    "        shap_values_y2_retrained = explainer_y2_retrained.shap_values(X_y2[test_idX_y2])\n",
    "        for SHAPs in shap_values_y2_retrained[1]:\n",
    "            shap_scores_y2_retrained.append(SHAPs) \n",
    "        shaps_y2_retrained_per_fold[i] = shap_values_y2_retrained[1]\n",
    "\n",
    "        #step 9) \n",
    "\n",
    "        study = optuna.create_study(direction=\"maximize\", study_name='TabNet optimization')\n",
    "        study.optimize(lambda trial: Objective(trial,X_y2[train_idX_y2], y_y2[train_idX_y2].flatten()), timeout=6*60) \n",
    "        TabNet_params = study.best_params\n",
    "\n",
    "        final_params = dict(n_d=TabNet_params['n_da'], n_a=TabNet_params['n_da'],\n",
    "                     n_steps=TabNet_params['n_steps'], \n",
    "                     gamma=TabNet_params['gamma'],\n",
    "                      n_shared=TabNet_params['n_shared'])\n",
    "        epochs = TabNet_params['epochs']\n",
    "\n",
    "        print('\\n        Best ACCURACY y2 CV model %.2f%%' % (study.best_value * 100))\n",
    "        print('        Best parameters:', study.best_params)\n",
    "\n",
    "        best_model_y2 = TabNetClassifier(**final_params)\n",
    "        best_model_y2.fit(X_train=X_y2[train_idX_y2], y_train=y_y2[train_idX_y2].flatten(), \n",
    "                    patience=TabNet_params['patience'], max_epochs=epochs,\n",
    "                        batch_size=64,\n",
    "                    eval_metric=['balanced_accuracy'])\n",
    "        \n",
    "        # step 10)\n",
    "        y_pred = best_model_y2.predict(X_y2[test_idX_y2])\n",
    "        outer_scores_y2_cv.append(balanced_accuracy_score(y_y2[test_idX_y2], y_pred))\n",
    "        print('ACCURACY y2 after CV (on outer test fold) %.2f%%' % (outer_scores_y2_cv[-1]*100))\n",
    "        probas_y2_cv = best_model_y2.predict_proba(X_y2[test_idX_y2])[:,1]\n",
    "        psi_scores_y1_y2_cv.append(psi(probas_y1,\n",
    "                                        probas_y2_cv))\n",
    "\n",
    "        #step 11)\n",
    "        explainer_y2_cv = shap.KernelExplainer(best_model_y2.predict_proba, shap.sample(X_y2[train_idX_y2], 100))\n",
    "        shap_values_y2_cv = explainer_y2_cv.shap_values(X_y2[test_idX_y2])\n",
    "        for SHAPs in shap_values_y2_cv[1]:\n",
    "            shap_scores_y2_cv.append(SHAPs)\n",
    "        shaps_y2_cv_per_fold[i] = shap_values_y2_cv[1]\n",
    "\n",
    "    return outer_scores_y1, shap_scores_y1, outer_scores_y2,\\\n",
    "          shap_scores_y2, outer_scores_y2_retrained, shap_scores_y2_retrained,\\\n",
    "              outer_scores_y2_cv, shap_scores_y2_cv, ix_training_y1, ix_test_y1,\\\n",
    "                  ix_training_y2, ix_test_y2,shaps_y1_per_fold, shaps_y2_per_fold,\\\n",
    "          shaps_y2_retrained_per_fold, shaps_y2_cv_per_fold,\\\n",
    "          psi_scores_y1_y2,\\\n",
    "              psi_scores_y1_y2_retrained, psi_scores_y1_y2_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_outer_scores_y1, tab_shap_scores_y1, tab_outer_scores_y2, tab_shap_scores_y2, tab_outer_scores_y2_retrained,\\\n",
    "      tab_shap_scores_y2_retrained, tab_outer_scores_y2_cv, tab_shap_scores_y2_cv, tab_ix_training_y1, tab_ix_test_y1,\\\n",
    "          tab_ix_training_y2, tab_ix_test_y2, tab_shaps_y1_per_fold, tab_shaps_y2_per_fold,\\\n",
    "          tab_shaps_y2_retrained_per_fold, tab_shaps_y2_cv_per_fold,\\\n",
    "            tab_psi_scores_y1_y2,\\\n",
    "              tab_psi_scores_y1_y2_retrained, tab_psi_scores_y1_y2_cv = run_models_TabNet( TabNetClassifier(verbose=0,seed=42), 'TabNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = independent_features\n",
    "\n",
    "resultX = pd.DataFrame(tab_shap_scores_y1, columns = feature_names)\n",
    "vals = np.abs(resultX.values).mean(0)\n",
    "shap_importance_tab = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance_tab.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance_tab['Rank'] = len(stats.rankdata(shap_importance_tab['feature_importance_vals'])) \\\n",
    "    - stats.rankdata(shap_importance_tab['feature_importance_vals']) + 1\n",
    "\n",
    "resultX = pd.DataFrame(tab_shap_scores_y2, columns = feature_names)\n",
    "vals = np.abs(resultX.values).mean(0)\n",
    "shap_importance_tab_y2 = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance_tab_y2.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance_tab_y2['Rank'] = len(stats.rankdata(shap_importance_tab_y2['feature_importance_vals'])) \\\n",
    "    - stats.rankdata(shap_importance_tab_y2['feature_importance_vals']) + 1\n",
    "\n",
    "resultX = pd.DataFrame(tab_shap_scores_y2_retrained, columns = feature_names)\n",
    "vals = np.abs(resultX.values).mean(0)\n",
    "shap_importance_retrained_tab_y2 = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance_retrained_tab_y2.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance_retrained_tab_y2['Rank'] = len(stats.rankdata(shap_importance_retrained_tab_y2['feature_importance_vals'])) \\\n",
    "      - stats.rankdata(shap_importance_retrained_tab_y2['feature_importance_vals']) + 1\n",
    "\n",
    "resultX = pd.DataFrame(tab_shap_scores_y2_cv, columns = feature_names)\n",
    "vals = np.abs(resultX.values).mean(0)\n",
    "shap_importance_tab_cv_y2 = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance_tab_cv_y2.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance_tab_cv_y2['Rank'] = len(stats.rankdata(shap_importance_tab_cv_y2['feature_importance_vals'])) \\\n",
    "    - stats.rankdata(shap_importance_tab_cv_y2['feature_importance_vals']) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(tab_shap_scores_y1, columns=independent_features).to_excel(f'results/{course_name}_SHAP_scores_TAB_{year_start}.xlsx')\n",
    "pd.DataFrame(tab_shap_scores_y2, columns=independent_features).to_excel(f'results/{course_name}_SHAP_scores_TAB_{year_finish}.xlsx')\n",
    "pd.DataFrame(tab_shap_scores_y2_retrained, columns=independent_features).to_excel(f'results/{course_name}_SHAP_scores_TAB_{year_finish}_retrained.xlsx')\n",
    "pd.DataFrame(tab_shap_scores_y2_cv, columns=independent_features).to_excel(f'results/{course_name}_SHAP_scores_TAB_{year_finish}_cv.xlsx')\n",
    "pd.DataFrame({f'TAB {year_start}': tab_outer_scores_y1, f'TAB {year_finish}': tab_outer_scores_y2, \n",
    "              f'TAB {year_finish} retrained': tab_outer_scores_y2_retrained,\n",
    "                f'TAB {year_finish} cv': tab_outer_scores_y2_cv }).to_excel(f'results/{course_name}_TAB_performance.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(f'results/{course_name}_SHAP_scores_TAB_{year_start}_per_fold.xlsx', engine='xlsxwriter') as writer:\n",
    "    for i in range(10):\n",
    "\n",
    "        sheet_name = f'Sheet{i+1}' \n",
    "        pd.DataFrame(tab_shaps_y1_per_fold[i]).to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "with pd.ExcelWriter(f'results/{course_name}_SHAP_scores_TAB_{year_finish}_per_fold.xlsx', engine='xlsxwriter') as writer:\n",
    "    for i in range(10):\n",
    "\n",
    "        sheet_name = f'Sheet{i+1}'  \n",
    "        pd.DataFrame(tab_shaps_y2_per_fold[i]).to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "with pd.ExcelWriter(f'results/{course_name}_SHAP_scores_TAB_{year_finish}_retrained_per_fold.xlsx', engine='xlsxwriter') as writer:\n",
    "    for i in range(10):\n",
    "\n",
    "        sheet_name = f'Sheet{i+1}'  \n",
    "        pd.DataFrame(tab_shaps_y2_retrained_per_fold[i]).to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "with pd.ExcelWriter(f'results/{course_name}_SHAP_scores_TAB_{year_finish}_cv_per_fold.xlsx', engine='xlsxwriter') as writer:\n",
    "    for i in range(10):\n",
    "\n",
    "        sheet_name = f'Sheet{i+1}' \n",
    "        pd.DataFrame(tab_shaps_y2_cv_per_fold[i]).to_excel(writer, sheet_name=sheet_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_psi = pd.DataFrame({'Model X on data X vs. Model X on data X+1':tab_psi_scores_y1_y2, \n",
    "                        'Model X on data X vs. Model X retrained on data X+1':tab_psi_scores_y1_y2_retrained,\n",
    "                          'Model X on data X vs. Model X+1 on data X+1':tab_psi_scores_y1_y2_cv})\n",
    "tab_psi.to_excel(f'results/{course_name} {year_start} vs. {year_finish} TAB PSI.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/{course_name} {year_start} TAB train indices.pickle', 'wb') as handle:\n",
    "    pickle.dump(tab_ix_training_y1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'results/{course_name} {year_start} TAB test indices.pickle', 'wb') as handle:\n",
    "    pickle.dump(tab_ix_test_y1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'results/{course_name} {year_finish} TAB train indices.pickle', 'wb') as handle:\n",
    "    pickle.dump(tab_ix_training_y2, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'results/{course_name} {year_finish} TAB test indices.pickle', 'wb') as handle:\n",
    "    pickle.dump(tab_ix_test_y2, handle, protocol=pickle.HIGHEST_PROTOCOL)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
